{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import shutil\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from colorsys import rgb_to_hsv\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 이미지 파일명 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "색 정보를 추출할 이미지의 파일명을 모두 불러온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get_file_names(img_path, ends, sample_ratio = 1)\n",
    "- 이미지 경로 (img_path) 상에 있는 특정 확장자 파일명을 모두 읽어들인다.\n",
    " - sample_ratio 에 0~1값을 넣어 샘플링이 가능하다.\n",
    "- 읽어들인 파일명을 리스트에 저장한 뒤 return 한다\n",
    "- [ex] file_names = get_file_names('images/', 'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(img_path, ends, sample_ratio = 1):\n",
    "    file_names = []\n",
    "\n",
    "    with os.scandir(img_path) as files:\n",
    "        for file in files:\n",
    "            # .jpg .png 등 확장자명이 'g'로 끝나는 파일들 모두 읽기\n",
    "            if file.name.endswith(ends):\n",
    "                file_names.append(img_path + file.name)\n",
    "\n",
    "    if sample_ratio < 1:\n",
    "        file_names = random.sample(file_names, int(len(file_names) * sample_ratio))\n",
    "        \n",
    "    return file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 추출하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지의 색 정보를 추출하는 방법에 대해 다양한 방법을 시도하였다. 기본적인 아이디어는 불러온 이미지로부터 각 픽셀의 색을 모두 구하는 것에서 시작된다. 가장 먼저 접근한 방식은 단순히 RGB 채널로 불러온 이미지의 픽셀들을 총 30개의 클러스터로 분류한 뒤, 작품 별 클러스터의 관계성으로부터 작품을 분류하고자 하였다. 그러나 RGB 채널의 값은 HSV 채널, YUV 채널에 비해 실제 우리가 눈으로 인식하는 색들을 표현하는 데 있어서 표현력이 좋지 않았으며 실제로 분류 결과도 타당하지 못했다. 따라서 우리는 여러 채널의 혼합 및 시행 착오를 겪을 필요가 있었고, 최종적으로 HSV채널과 YUV채널을 합친 데이터를 사용하기로 하였다. (2-3. HSV-YUV data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. HSV flatten data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract_data_hsv_flatten(file_name, img_size = (360, 360), img_grid = 5, clr_grid = (12, 8, 8))\n",
    "- cv2 라이브러리를 통해 RGB 채널로 읽어들인 이미지를 HSV로 변환한 뒤, 그리드에 맞게 팔레트 내의 색을 평면화 한다\n",
    " - 1. 먼저 이미지를 RGB 채널로 읽고, HSV채널로 변환한다. (각 채널별 range는 180,256,256 이다)\n",
    " - 2. 몇 분할로 나눌지를 파라미터로 넘겨받아 H, S, V를 각각 분해하고 평면화 한다.\n",
    " - 3. default 의 경우 H, S, V가 각각 12, 8, 8 개로 분해되어 그림 내의 픽셀들이 768 컬럼 중 한 군데로 분류된다.\n",
    "- 평면화된 데이터를 return 한다 (default shape : (1, 768))\n",
    "- [ex] flt_data = extract_data_hsv_flatten(file_names[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_hsv_flatten(file_name, img_size = (360, 360), img_grid = 5, clr_grid = (12, 8, 8)):\n",
    "    img = cv2.imread(file_name)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    grid_count = np.zeros([img_grid * 2, clr_grid[0] * clr_grid[1] * clr_grid[2]])\n",
    "    clr_data = []\n",
    "    for i, row in enumerate(img):\n",
    "        for j, col in enumerate(row):\n",
    "            newH = (int)((img_hsv[i][j][0] / 180) * clr_grid[0]) #range of H : 0 ~ 179\n",
    "            newS = (int)((img_hsv[i][j][1] / 256) * clr_grid[1]) #range of S : 0 ~ 255\n",
    "            newV = (int)((img_hsv[i][j][2] / 256) * clr_grid[2]) #range of V : 0 ~ 255\n",
    "            label = newH * clr_grid[1] * clr_grid[2] + newS * clr_grid[2] + newV\n",
    "            grid_count[(int)((i / img_size[0]) * img_grid)][label] += 1\n",
    "            grid_count[img_grid + (int)((i / img_size[0]) * img_grid)][label] += 1\n",
    "    for i, grid in enumerate(grid_count):\n",
    "        grid_total = grid_count[i].sum()\n",
    "        clr_data.append(grid_count[i] / grid_total) \n",
    "    return np.array(clr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. RGB-HSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract_data_rgbhsv_before(file_name, img_size = (360, 360))\n",
    "- keras 라이브러리를 통해 BGR 채널로 읽어들인 이미지를 rgb_to_hsv 함수를 통해 HSV 채널로 변환한다.\n",
    " - 이 때, 이미지는 1차원으로 reshape 해준다 (360x360x3→129600x3)\n",
    "- 평면화된 RGB + HSV데이터를 return 한다 (default shape : (129600, 6))\n",
    "- [ex] clr_data = extract_data_rgbhsv_before(file_names[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.rgb_to_hsv version (구버전)\n",
    "def extract_data_rgbhsv_before(file_name, img_size = (360, 360)):\n",
    "    img = load_img(file_name, target_size = img_size)\n",
    "    img = np.array(img)\n",
    "    img = img.reshape(img_size[0] * img_size[1], 3)\n",
    "    hsv_data = []\n",
    "    for pixel in img:\n",
    "        hsv_data.append(rgb_to_hsv(pixel[0] / 255, pixel[1] / 255, pixel[2] / 255))\n",
    "    return np.concatenate((img / 255, hsv_data), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract_data_rgbhsv(file_name, img_size = (360, 360))\n",
    "- cv2 라이브러리를 통해 RGB 채널로 읽어들인 이미지를 HSV로 변환한다.\n",
    " - 이 때, 이미지는 1차원으로 reshape 해준다 (360x360x3→129600x3)\n",
    "- 평면화된 RGB + HSV데이터를 return 한다 (default shape : (129600, 6))\n",
    "- [ex] clr_data = extract_data_rgbhsv(file_names[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_rgbhsv(file_name, img_size = (360, 360)):\n",
    "    img = cv2.imread(file_name)\n",
    "    img = cv2.resize(img, img_size) \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).reshape(img_size[0] * img_size[1], 3)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).reshape(img_size[0] * img_size[1], 3)\n",
    "    return np.concatenate((img_rgb, img_hsv), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. HSV-YUV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract_data_hsvyuv(file_name, img_size = (360, 360))\n",
    "- cv2 라이브러리를 통해 BGR 채널로 읽어들인 이미지를 HSV 및 YUV로 변환한다.\n",
    " - 이 때, 이미지는 1차원으로 reshape 해준다 (360x360x3→129600x3)\n",
    "- 평면화된 HSV + YUV데이터를 return 한다 (default shape : (129600, 6))\n",
    "- [ex] clr_data = extract_data_hsvyu(file_names[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_hsvyuv(file_name, img_size = (360, 360)):\n",
    "    img = cv2.imread(file_name)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV).reshape(img_size[0] * img_size[1], 3)\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV).reshape(img_size[0] * img_size[1], 3)\n",
    "    return np.concatenate((img_hsv, img_yuv), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 클러스터링 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지로 부터 추출해 낸 색 데이터를 총 몇개의 클러스터로 나눌 것인가에 대한 고민도 많이 이루어졌다. 클러스터의 개수를 유동적으로 조절하기에는 너무 많은 계산 시간을 필요로 하였으며, 클러스터 개수가 지나치게 많으면 추후 분류 작업에서 불필요한 색까지 모두 중요한 데이터로 인식되는 경향을 보였다. 반면 클러스터 개수가 지나치게 적으면 완전 다른 작품도 비슷한 작품으로 분류되는 경향성을 보였고 최종적으로 우리는 15~25개의 클러스터에서 가장 안정적인 결과를 구할 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get_clu_labels(data, cluster = 25, state = 2021)\n",
    "- KMeans 군집화를 통해 전체 색 데이터에 대응하는 클러스터 레이블을 얻는다.\n",
    " - cluster 파라미터를 통해 레이블 개수를 조절할 수 있다.\n",
    "- 클러스터 레이블을 return 한다 (default shape : (129600, 1))\n",
    "- [ex] data_labels = get_clu_labels(clr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clu_labels(data, cluster = 25, state = 2021):\n",
    "    km = KMeans(n_clusters = cluster, random_state = state)\n",
    "    km.fit(data)\n",
    "    return km.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Visualization with each cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show_img_with_clusters(file_name, labels, img_size = (360, 360), grid_size = (5, 5), clu_color = (0, 255, 0))\n",
    "- 각 군집 결과 별로 그림 상에 어느 부분에 해당하는지 시각화하여 보여준다.\n",
    " - grid_size : subplot 형태로 0번 클러스터부터 N번 클러스터까지 표현할 충분할 크기가 보장되어야 한다 (default : 5x5 = 25)\n",
    " - clu_color : 해당 클러스터를 어떤 색으로 표현할 지 RGB로 입력할 수 있다 (default : GREEN)\n",
    "- [ex] show_img_with_clusters(file_names[target], data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_with_clusters(file_name, labels, img_size = (360, 360), grid_size = (5, 5), clu_color = (0, 255, 0)):\n",
    "    plt.figure(figsize = (25, 25))\n",
    "    img = load_img(file_name, target_size = img_size)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    for idx in range(grid_size[0] * grid_size[1]):\n",
    "        img_now = img.copy()\n",
    "        new_labels =  np.array(list(map(lambda x: x == idx, labels))).reshape(img_size)\n",
    "        for i, row in enumerate(img):\n",
    "            for j, col in enumerate(row):\n",
    "                if new_labels[i][j]:\n",
    "                    img_now[i][j] = clu_color\n",
    "        plt.subplot(grid_size[1], grid_size[0] ,idx + 1);\n",
    "        plt.imshow(img_now)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. Visualization with grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show_img_with_grid(file_name, labels, img_size = (360, 360), grid = (8, 8), cluster = 25, ratio = 0.1, clu_color = (0, 255, 0))\n",
    "- 그림을 grid 개수에 맞게 분할한 뒤, 특정 클러스터가 해당 영역을 일정 비율만큼 차지하는지를 시각화하여 보여준다\n",
    " - grid : 그림을 얼만큼 분해할 지 정한다 (default : 8x8)\n",
    " - cluster : 레이블을 구할 때 입력했던 클러스터 개수를 입력해주어야 한다 (default : 25)\n",
    " - ratio : 넘지 못했을 때 손실시키기 위한 비율을 설정할 수 있다 (dafault : 0.1)\n",
    " - clu_color : 손실된 클러스터를 어떤 색으로 표현할 지 RGB로 입력할 수 있다 (default : GREEN)\n",
    "- [ex] show_img_with_grid(file_names[target], data_labels, ratio = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_with_grid(file_name, labels, img_size = (360, 360), grid = (8, 8), cluster = 25, ratio = 0.1, clu_color = (0, 255, 0)):\n",
    "    plt.figure(figsize = (25, 25))\n",
    "    img = load_img(file_name, target_size = img_size)\n",
    "    img = np.array(img)\n",
    "    new_labels =  labels.reshape(img_size)\n",
    "    grid_count = np.zeros([grid[0] * grid[1], cluster])\n",
    "    for i, row in enumerate(img):\n",
    "        for j, col in enumerate(row):\n",
    "            grid_num = (int)(i / (img_size[0] / grid[0])) * grid[1] + (int)(j / (img_size[1] / grid[1]))\n",
    "            grid_count[grid_num][new_labels[i][j]] += 1\n",
    "    for i, row in enumerate(img):\n",
    "        for j, col in enumerate(row):\n",
    "            grid_num = (int)(i / (img_size[0] / grid[0])) * grid[1] + (int)(j / (img_size[1] / grid[1]))\n",
    "            if grid_count[grid_num][new_labels[i][j]] < (int)(img_size[0] * img_size[1] / grid[0] / grid[1] * ratio):\n",
    "                img[i][j] = clu_color\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 클러스터 데이터 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클러스터링을 통해 각 픽셀이 어떤 클러스터에 속하는지를 알 수 있게 되었는데, 우리는 이를 통해 각 클러스터가 실제 작품의 어느 부분에 존재하는지를 관찰할 수 있었다. 그 중에서는 한 군데에 밀집된 클러스터가 존재하는 반면 동시에 작품의 곳곳에 산개한 클러스터도 존재하였으며, 작품 비율의 대부분을 차지하는 클러스터도 존재하였다. 이러한 정보를 반영하기 위해 우리는 각 클러스터 별 색의 평균값과 클러스터의 중심 좌표, 그리고 모든 픽셀들이 중심으로부터 얼마나 떨어져있는지를 평균 거리 및 거리의 표준 편차를 통해 확인하고 최종적으로 픽셀 개수를 통해 클러스터가 작품에 차지하는 비율을 구하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. 클러스터 RGB평균, 중심 좌표, 평균 거리, 평균 표준편차, 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### grouping_clusters(file_name, labels, img_size = (360, 360), cluster = 25)\n",
    "- 각 클러스터 레이블을 기준으로 다양한 정보를 추출한다.\n",
    " - 1. 레이블의 RGB 평균 값 (0, 1, 2 columns)\n",
    " - 2. 이미지 상에서 중심 좌표 (3, 4 columns)\n",
    " - 3. 중심 좌표로부터의 픽셀 거리들의 평균 (5 column)\n",
    " - 4. 중심 좌표로부터의 픽셀 거리들의 표준편차 (6 column)\n",
    " - 5. 해당 클러스터가 작품에서 차지하는 비율 (7 column)\n",
    "- 추출한 정보를 취합하여 return 한다. (default shape : (25, 7))\n",
    "- [ex] clu_data = grouping_clusters(file_names[target], data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouping_clusters(file_name, labels, img_size = (360, 360), cluster = 25):\n",
    "    img = cv2.imread(file_name)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).reshape(img_size[0] * img_size[1], 3)\n",
    "    \n",
    "    rgbs = np.array([img_rgb[labels == i].mean(axis = 0) for i in range(cluster)])\n",
    "    \n",
    "    center_info = np.zeros([cluster, 3])\n",
    "    new_labels = labels.reshape(img_size[0], img_size[1])\n",
    "    for i in range(img_size[0]):\n",
    "        for j in range(img_size[1]):\n",
    "            tar = new_labels[i][j]\n",
    "            center_info[tar] += [i, j, 1]    \n",
    "    centers = np.array([[x / z,y / z] for [x,y,z] in center_info])\n",
    "    ratios = np.array([[z / (img_size[0] * img_size[1])] for [x,y,z] in center_info])\n",
    "    \n",
    "    dist_info = [[] for i in range(cluster)]\n",
    "    for i in range(img_size[0]):\n",
    "        for j in range(img_size[1]):\n",
    "            tar = new_labels[i][j]\n",
    "            dist_info[tar].append(norm(centers[tar] - [i, j]))\n",
    "    dists = np.array([[np.mean(data), np.std(data)] for data in dist_info])\n",
    "\n",
    "    return np.concatenate((rgbs, centers, dists, ratios), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Visualization with cluster quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show_img_with_cluster_quality(file_name, labels, clu_data, img_size = (360, 360))\n",
    "- 그림에 존재하는 모든 색을 클러스터의 평균 색으로 치환한다. 즉 그림을 클러스터 개수만큼의 색으로 재표현한다.\n",
    " - 4-1 에서 구한 RGB 평균 값을 활용한다\n",
    "- [ex] show_img_with_cluster_quality(file_names[target], data_labels, clu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_with_cluster_quality(file_name, labels, clu_data, img_size = (360, 360)):\n",
    "    plt.figure(figsize = (25, 25))\n",
    "    img = load_img(file_name, target_size = img_size)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    new_labels =  labels.reshape(img_size)\n",
    "    for i, row in enumerate(img):\n",
    "        for j, col in enumerate(row):\n",
    "            img[i][j] = clu_data[new_labels[i][j]][0 : 3]\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. Visualization with color ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show_clu_by_ratio(clu_data)\n",
    "- 각 클러스터 레이블이 그림 내에서 어떤 색을 대표하고, 그림 내의 비율이 얼마인지를 시각화한다.\n",
    " - barh plot 형태로 시각화한다.\n",
    " - 4-1 에서 구한 RGB 평균 값, 비율 값을 활용한다\n",
    "- [ex] show_clu_by_ratio(clu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_clu_by_ratio(clu_data):\n",
    "    plt.figure(figsize = (8, 8))\n",
    "    clu_data_sorted = clu_data[np.argsort(clu_data[:, 7])]\n",
    "    plt.barh(range(len(clu_data)), clu_data_sorted[:, 7], color = clu_data[:, 0:3].astype(int)/256)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. Visualization with color position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show_clu_by_pos(clu_data)\n",
    "- 각 클러스터 레이블의 중심이 그림에서 어디에 존재하는지를 시각화한다.\n",
    " - scatter plot 형태로 시각화한다.\n",
    " - 4-1 에서 구한 RGB 평균 값, 비율 값을 활용한다\n",
    " - scatter 의 크기는 비율 값에 비례하도록 표현하였다.\n",
    "- [ex] show_clu_by_pos(clu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_clu_by_pos(clu_data):\n",
    "    plt.figure(figsize = (8, 8))\n",
    "    plt.xlim([0, 360])\n",
    "    plt.ylim([0, 360])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.scatter(x = clu_data[:, 4], y = clu_data[:, 3], s= clu_data[:,7] * 10000, c = clu_data[:, 0:3].astype(int)/256)\n",
    "    for i in range(len(clu_data)):\n",
    "        plt.text(x = clu_data[i, 4] - 1.2, y = clu_data[i, 3] + 0.4, s = str(i), size = 'small')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 데이터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클러스터링은 n=20 기준으로 약 10시간이 걸릴 정도로 오랜 작업을 요구했다. 따라서 이 후 분류 작업을 원활하게 수행하기 위해 데이터를 추출한 후 저장하는 과정을 포함해야 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save_clu_data(save_path, file_name, data)\n",
    "- 그림으로 부터 추출한 클러스터 정보를 저장한다\n",
    " - 저장 경로에 해당하는 디렉토리가 없으면 만들어준다\n",
    " - 이미지 파일 명을 가져와 확장자만 npy로 변경하여 저장한다\n",
    "- [ex] save_clu_data('my_save/', file_names[target], clu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clu_data(save_path, file_name, data):\n",
    "    try:\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  save_path)\n",
    "    try:\n",
    "        save_name = save_path + file_name.rsplit('.')[0].rsplit('/')[-1] + \".npy\"\n",
    "        np.save(save_name, data)\n",
    "    except:\n",
    "        print ('Error: Creating Data. ' + save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1~5. Extract Color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### extract_color_v1(img_path, save_path, img_size = (360, 360), clu = 25)\n",
    "- 이미지로부터 클러스터 정보를 읽어오는 과정을 취합하였다.\n",
    " - 저장 경로에 이미 해당 데이터가 존재하면 과정을 생략하도록 설계하였다.\n",
    "- [ex] extract_color_v1('images/', 'my_save/', clu = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_v1(img_path, save_path, img_size = (360, 360), clu = 25):\n",
    "    file_names = get_file_names(img_path, 'jpg', 1)\n",
    "    for target_name in tqdm(file_names):\n",
    "        save_name = save_path + target_name.rsplit('.')[0].rsplit('/')[-1] + \".npy\"\n",
    "        if not os.path.isfile(save_name):\n",
    "            hsvyuv_data = extract_data_hsvyuv(target_name, img_size = img_size)\n",
    "            data_labels = get_clu_labels(hsvyuv_data, cluster = clu)\n",
    "            clu_data = grouping_clusters(target_name, data_labels, cluster = clu)\n",
    "            save_clu_data(save_path, target_name, clu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 클러스터 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 별로 기존에 작업했던 클러스터 데이터를 모두 로드한다. 이 때 이미지의 개수와 클러스터 행렬의 행 개수가 일치하는지 반드시 확인할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load_clu_data(data_path, sample_ratio = 1)\n",
    "- 데이터 경로 (data_path) 상에 있는 .npy 확장자 파일명을 모두 로드한다.\n",
    " - sample_ratio 에 0~1값을 넣어 샘플링이 가능하다.\n",
    "- 읽어들인 파일명을 ndarray 형식으로 return 한다 (default shape : (5411, 25, 7)) *이미지 개수 = 5411\n",
    "- [ex] file_names = get_file_names('images/', 'jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clu_data(data_path, sample_ratio = 1):\n",
    "    clu_data = []\n",
    "\n",
    "    with os.scandir(data_path) as files:\n",
    "        for file in files:\n",
    "            if file.name.endswith('npy'):\n",
    "                clu_data.append(np.load(file))\n",
    "    if sample_ratio < 1:\n",
    "        clu_data = random.sample(clu_data, int(len(clu_data) * sample_ratio))\n",
    "        \n",
    "    return np.array(clu_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 데이터 평면화 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 이미지마다 클러스터의 개수 및 각 클러스터의 특징값을 지니고 있었기 때문에 이미지는 2차원의 데이터로 표현되었다. 여기에 이미지의 개수를 포함하면 데이터는 3차원이 되었고 이는 머신 러닝 데이터로 적합하지 않았다. 따라서 우리는 데이터를 1차원으로 평면화하는 작업을 수행할 필요가 있었다. 평면화 작업은 각 클러스터가 가진 RGB 값과 클러스터의 비율을 기반으로 수행되었다. RGB값이 0~1로 표현되었을 때, 이를 적절하게 k개로 분할해주면 k * k * k 개의 인덱스로 표현이 가능했다. k가 너무 크면 sparce space 가 너무 많이 생기고, k가 너무 적으면 다른 색이어도 동일한 인덱스에 할당될 가능성이 있었기 때문에 주의가 필요했다. 우리는 30개의 클러스터를 5x5x5 = 125개의 인덱스에 할당하는 것이 가장 적합하다고 판단하였고 k=4 또는 k=8일때보다 훨씬 괜찮은 성능을 보이는 것을 관찰할 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### flatten_clusters_rgb(clu_data, div = 5)\n",
    "- 클러스터의 RGB 평균값을 기준으로 그리드에 맞게 색을 평면화 한다\n",
    " - div : 몇 분할로 나눌지를 파라미터로 넘겨받는다. (default : 5, 5x5x5 →125 columns)\n",
    " - 시각에 민감한 색이 G, R, B 순임으로 차수를 이와 같이 정해 민감한 색의 컬럼을 최대한 떨어트린다.\n",
    "- 평면화된 데이터를 return 한다 (default shape : (5411, 125))\n",
    "- [ex] flt_data = flatten_clusters_rgb(clu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_clusters_rgb(clu_data, div = 5):\n",
    "    flt_data = []\n",
    "    for feature in clu_data: \n",
    "        R = ((feature[:,0] / 256) * div).astype(int)\n",
    "        G = ((feature[:,1] / 256) * div).astype(int)\n",
    "        B = ((feature[:,2] / 256) * div).astype(int)\n",
    "        tar = G * div * div + R * div + B\n",
    "        new_row = np.zeros(div ** 3)\n",
    "        for num, val in zip(tar, feature[:, -1]):\n",
    "            new_row[num] += val\n",
    "        flt_data.append(new_row)\n",
    "    return np.array(flt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 차원 축소 (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터의 컬럼 수가 여전히 많으므로 차원 축소 기법을 수행하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### reduction_feature_pca(flt_data, threshold = 0.99)\n",
    "- PCA 기법을 통해 데이터의 컬럼(차원)을 축소한다.\n",
    " - threshold : 정보 유지율을 파라미터로 전달받는다 (default : 0.99)\n",
    "- 변환된 데이터를 return 한다 (default shape : (5411, d))\n",
    "- [ex] pca_data = reduction_feature_pca(flt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduction_feature_pca(flt_data, threshold = 0.99):\n",
    "    pca = PCA(n_components = len(flt_data[0]), random_state = 2021)\n",
    "    pca.fit_transform(flt_data)\n",
    "    \n",
    "    ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "    d = np.argmax(ratio >= threshold) + 1\n",
    "    \n",
    "    pca = PCA(n_components = d, random_state = 2021)\n",
    "    return pca.fit_transform(flt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 작품 클러스터링 및 그룹화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "작품마다 생성된 색상 행렬을 기반으로 작품의 클러스터링을 수행하였다. 처음에 우리는 작품의 색 구성이 단조로운 작품들이 구성이 풍부한 작품보다 계층이 높을 필요가 있다고 판단하여 계층적 클러스터링 (hierarchical clustering) 및 밀도 기반 클러스터링을 수행하였다. 그러나 작품이 내재한 색상의 다양성은 이러한 클러스터로 모두 표현할 수 없었는데, 두 가지 클러스터 기법의 경우 특정 클러스터에 매우 적은 작품 수를 할당하는 문제가 발생하였다. 따라서 우리는 이를 단순 유클리드 거리 기반으로 한 K-means 알고리즘을 통해 해소하고자 하였으며 결과는 기존의 클러스터링 기법에 비해 준수한 분포를 이루었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9-1. Labels (3-1 과 동일)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get_clu_labels(data, cluster = 25, state = 2021)\n",
    "- KMeans 군집화를 통해 각 작품 별 클러스터 레이블을 얻는다.\n",
    " - cluster 파라미터를 통해 레이블 개수를 조절할 수 있다. 작품 수가 5411개 이므로 clu = 50 이상의 환경에서 분류를 수행할 필요가 있다.\n",
    "- 클러스터 레이블을 return 한다 (default shape : (129600, 1))\n",
    "- [ex] data_labels = get_clu_labels(clr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9-2. Visualization with groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### show_img_by_group(img_path, labels, group_num, grid = (7, 3), img_size = (360, 360))\n",
    "- 작품 별 레이블을 기반으로 동일한 레이블을 가진 작품들을 그룹으로 보여준다\n",
    " - grid = 작품을 subplot 형식으로 보여주며 개수를 조절할 수 있다 (default = (7, 3) → 21개)\n",
    "- [ex] show_img_by_group(file_names, data_labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img_by_group(img_path, labels, group_num, grid = (7, 3), img_size = (360, 360)):\n",
    "    plt.figure(figsize = (grid[0] * 3, grid[1] * 3))\n",
    "    group = []\n",
    "    for path, label in zip(img_path, labels):\n",
    "        if label == group_num:\n",
    "            group.append(path)\n",
    "    \n",
    "    print(f\"Cluster size : {len(group)}\")\n",
    "    for idx in range(min(grid[1] * grid[0], len(group))):\n",
    "        \n",
    "        plt.subplot(grid[1], grid[0] ,idx+1);\n",
    "        img = load_img(group[idx], target_size = img_size)\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 작품 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분류 결과를 직접 확인하기 위해 폴더 별로 동일한 클러스터를 가진 이미지를 저장한 후 관찰하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save_groups(save_path, img_path, labels)\n",
    "- 작품 별 레이블을 기반으로 작품들을 분류하여 저장한다.\n",
    " - shutil 라이브러리의 copyfile 을 통해 이미지를 복사해오는 방식으로 저장하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_groups(save_path, img_path, labels):\n",
    "    for img, label in zip(img_path, labels):\n",
    "        result_path = save_path + str(label) + \"/\"\n",
    "        try:\n",
    "            if not os.path.exists(result_path):\n",
    "                os.makedirs(result_path)\n",
    "        except OSError:\n",
    "            print ('Error: Creating directory. ' +  result_path)   \n",
    "        shutil.copyfile(img, result_path + img.rsplit('/')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6~10. Clustering Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### clustering_images_v1(data_path, img_path, result_path, clu)\n",
    "- 클러스터 정보로부터 이미지를 분류하는 과정을 취합하였다.\n",
    " - data_path : 불러올 작품 클러스터 정보가 존재해야 한다.\n",
    " - img_path : 불러올 작품이 존재하며 data_path 상에 있는 데이터와 크기 및 이름 정보가 일치해야 한다\n",
    " - clu : 분류 개수를 정할 수 있다. (default = 50)\n",
    "- [ex] clustering_images_v1('my_save/', 'images/', 'my_results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_images_v1(data_path, img_path, result_path, clu = 50):\n",
    "    clu_data = load_clu_data(data_path)\n",
    "    flt_data = flatten_clusters_rgb(clu_data)\n",
    "    pca_data = reduction_feature_pca(flt_data)\n",
    "    img_names = get_file_names(img_path, 'jpg')\n",
    "    data_labels = get_clu_labels(pca_data, cluster = clu)\n",
    "    save_groups(result_path, img_names, data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 특징맵 생성 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추천 시스템을 구현하는 것은 작품을 분류하는 것과는 다른 특징을 필요로 하였다. Content-Based Filtering 을 수행하기 위해서는 작품 간의 관계를 파악하는 특징 값이 필요로 하였고, 우리는 두 작품의 특징을 하나의 값으로 표현하여 작품 수가 행과 열이 되는 정방행렬을 만드는 것을 새로운 목표로 하였다. 가장 먼저 접근한 방식은 코사인 유사도로, 평면화된 1차원 색상 행렬 두 개의 코사인 유사도를 저장하는 방식으로 정방행렬을 구성하였다. (11-2. Feature map with Cosine Similarity) 두번째는 아직 평면화되지 않은 색상 행렬에서 두 클러스터 집단의 1:1 매칭을 수행하는 방식으로 최소 비용을 저장하는 방식으로 정방행렬을 구성하였다. 이는 단순히 유량 문제 (Networkflow Problem) 으로 치환할 수 있었으나 시간 복잡도가 O(N^2 * C^5) 에 다다르는 결과를 초래하였다. 조사 결과 우리는 할당 문제 (Assignment Problem) 를 해결하는 헝가리안 알고리즘(Hungarian Algorithm) 및 이를 지원하는 라이브러리를 찾을 수 있었다. (11-4-4. Using linear_sum_assignment Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-1. Cosine Simillarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cos_sim(A, B)\n",
    "- 코사인 유사도 결과를 return 한다.\n",
    " - A, B : 차원이 동일한 1차 행렬\n",
    "- [ex] fmap[i][j] = cos_sim(data[i], data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(A, B):\n",
    "       return dot(A, B)/(norm(A)*norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-2. Feature map with Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature_map_cossim(data)\n",
    "- 2차원으로 구성된 데이터에서 두 행 간의 코사인 유사도를 구한다 (*이미지 개수 x 이미지 특징 벡터)\n",
    "- 행의 개수와 일치한 정방행렬을 return 한다. (default : N * N, N = 이미지 개수)\n",
    "- [ex] fmap = feature_map_cossim(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map_cossim(data):\n",
    "    N = len(data)\n",
    "    fmap = np.zeros([N, N])\n",
    "    for i in tqdm(range(N)):\n",
    "        for j in range(N):\n",
    "            fmap[i][j] = cos_sim(data[i], data[j])\n",
    "    return fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-3. Feature map scailing with Square Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### square_filter(val, m, M, reverse = False)\n",
    "- 최솟값이 m, 최댓값이 M 인 1차 행렬을 0~1 값으로 스케일링 했을 때의 val값을 알려준다.\n",
    " - val : 실제 구하고자 하는 input 값이다.\n",
    " - reverse : True이면 최솟값이 1, 최댓값이 0으로 스케일링이 이루어진다.\n",
    "- 사용되는 함수는 계수가 1인 x^2 함수이다.\n",
    "- 스케일링된 값을 return 한다.\n",
    "- [ex] new_val[j] = sqaure_filter(data[i][j], data[i].min(), data[i].max())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_filter(val, m, M, reverse = False):\n",
    "    if reverse:\n",
    "        return ((val - M) ** 2) / ((m - M) ** 2)\n",
    "    else:\n",
    "        return ((val - m) ** 2) / ((m - M) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature_map_dist_scaled(data, sigma = 0.5)\n",
    "- square_filter 를 기반으로 거리값을 구한 행렬을 0~1값으로 scailing 한다.\n",
    " - data[i][i] (동일한 데이터) 의 경우 거리 값이 무조건 0이 된다.\n",
    " - 이를 두번째 최솟값에서 표준편차x시그마 를 빼준 값으로 치환한다.\n",
    " - 최솟값이 0, 최댓값이 1인 reversed square filter 를 적용한다.\n",
    "- 스케일링된 행렬을 return 한다.\n",
    "- [ex] fmap = feature_map_dist_scaled(dist_data)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map_dist_scaled(data, sigma = 0.5):\n",
    "    N = len(data)\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            data[j][i] = data[i][j]\n",
    "    for i in range(N):\n",
    "        data[i][i] = np.unique(data[i])[1] - sigma * np.std(data[i])\n",
    "    return np.array([square_filter(nn, nn.min(), nn.max(), reverse = True) for nn in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-4. Feature map with Cluster Matching based on Minimal Cost Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11-4-1. Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### network_flow_init(clu = 25)\n",
    "- 유량 문제를 해결하기 위한 초기화 작업을 수행하였다.\n",
    " - 용량, 유량, 비용 행렬을 초기화 한다\n",
    " - 클러스터간 fully-connected layer를 생성한다\n",
    "- [ex] network_flow_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_flow_init(clu = 25):\n",
    "    global capacity, flow, cost, adj, INF, source, sink\n",
    "    v = 2 * clu + 2\n",
    "    capacity = [[0]*v for _ in range(v)] # 용량\n",
    "    flow = [[0]*v for _ in range(v)] # 유량\n",
    "    cost = [[0]*v for _ in range(v)] # 비용\n",
    "    adj = [[] for _ in range(v)] # 인접 그래프\n",
    "    INF = 9876543210\n",
    "    source = 2 * clu\n",
    "    sink = 2 * clu + 1\n",
    "\n",
    "    for i in range(clu):\n",
    "        adj[source].append(i)\n",
    "        adj[i].append(source)\n",
    "        capacity[source][i] = 1\n",
    "    for i in range(clu, 2 * clu):\n",
    "        adj[sink].append(i)\n",
    "        adj[i].append(sink)\n",
    "        capacity[i][sink] = 1\n",
    "    for i in range(clu):\n",
    "        for j in range(clu, 2 * clu):\n",
    "            adj[i].append(j)\n",
    "            adj[j].append(i)\n",
    "            capacity[i][j] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11-4-2. Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get_cost(now, tar)\n",
    "- 두 클러스터 간의 비용을 얼마로 할지를 정의하였다.\n",
    " - 기본적으로 유클리드 거리를 비용으로 상정하였으며, 작품이 가진 특징의 종류 별로 다른 가중치를 적용하여 비용 함수를 정의하였다.\n",
    " - w1 = 8 : RGB 채널이 작품의 인상을 가장 크게 결정짓기 때문에 가장 높은 비율을 할당할 필요가 있었다.\n",
    " - w2 = 3 : 우리는 작품 상에서 클러스터의 위치 또한 작품의 인상에 큰 요인을 준다는 것을 분류 작업을 통해 느낄 수 있었고, 이에 대한 가중치를 적용하였다.\n",
    " - w3 = 2 : 클러스터가 얼마나 산개해있는지를 나타내는 평균, 분산 값의 차이는 사실 상 매우 난해한 값으로 작용하였다. 이에 대해 적절한 가중치를 부여하였다.\n",
    " - w4 = 800 : 각 클러스터가 차지하는 비율은 n=25 기준 평균 4%에 불과하였고, 이들의 차이는 가장 많은 클러스터를 제외하면 0.01%p 정도에 불과했다. 이를 거리로 표현하면 매우 낮은 수치에 해당하였고 이를 어느정도 높일 필요가 있었다.\n",
    "- [ex] cost[i][j] = get_cost(data[i], data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost(now, tar):\n",
    "    diff_color = 8 * norm(now[0:3] - tar[0:3]) # RGB 차이\n",
    "    diff_pos = 3 * norm(now[3:5] - tar[3:5]) # 중심 좌표 차이\n",
    "    diff_dist = 2 * norm(now[5:7] - tar[5:7]) # 평균, 분산 차이\n",
    "    diff_ratio = 800 * norm(now[-1] - tar[-1]) # 비율 차이\n",
    "    return diff_color + diff_pos + diff_dist + diff_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11-4-3. MCMF Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### network_flow(now, tar, clu = 25)\n",
    "- 유량 문제를 해결하기 위한 알고리즘으로, 두 작품에 내재한 클러스터 간 1:1 매칭을 모두 수행하였을 때의 최소 비용을 계산한다.\n",
    " - 정점이 곧 클러스터 수이며, 모든 클러스터가 반대쪽 클러스터와 매칭될 가능성이 있으므로 간선의 개수는 (클러스터 수 ^ 2)이다.\n",
    " - 해당 유량 알고리즘의 시간 복잡도는 O(VE^2) 이므로 클러스터 개수를 C라고 하였을 때 최종 시간복잡도는 O(C^5) 이다.\n",
    "- 특징 맵을 구현하기 위해서는 N * N 번의 작업이 필요하므로 특징 맵 구현을 위한 시간복잡도는 O(N^2C^5)이다.\n",
    "- 두 작품의 클러스터 간 1:1 매칭을 수행하였을 때의 최소 비용을 return 한다.\n",
    "- [ex] fmap[x][y] = network_flow(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_flow(now, tar, clu = 25):\n",
    "    global capacity, flow, cost, adj, INF, source, sink\n",
    "    v = 2 * clu + 2\n",
    "    flow = [[0]*v for _ in range(v)] # 유량\n",
    "    cost = [[0]*v for _ in range(v)] # 비용\n",
    "    for i in range(clu):\n",
    "        for j in range(clu, 2 * clu):\n",
    "            cost[i][j] = get_cost(now[i], tar[j - clu])\n",
    "            cost[j][i] = -cost[i][j]\n",
    "        \n",
    "    answer = [0, 0] # 최소 비용, 최대 유량\n",
    "    while True:\n",
    "        path, dist = [-1]*v, [INF]*v\n",
    "        inQueue, queue = [0]*v, [source] # 다음에 방문할 정점들\n",
    "        dist[source], inQueue[source] = 0, 1\n",
    "        while queue:\n",
    "            present = queue[0] # 현재 정점\n",
    "            del queue[0]\n",
    "            inQueue[present] = False\n",
    "            for _next in adj[present]:\n",
    "                # 최소 비용이고, 최대 유량일 경우\n",
    "                if dist[_next] > dist[present] + cost[present][_next] and capacity[present][_next] - flow[present][_next] > 0:\n",
    "                    dist[_next], path[_next] = dist[present] + cost[present][_next], present\n",
    "                    if not inQueue[_next]:\n",
    "                        queue.append(_next)\n",
    "                        inQueue[_next] = 1\n",
    "        if path[sink] == -1: # 가능한 모든 경로를 찾았을 경우\n",
    "            break\n",
    "        # 현재 경로에서의 최소 유량 찾음\n",
    "        flowRate = INF\n",
    "        present = sink\n",
    "        while present != source:\n",
    "            previous = path[present]\n",
    "            flowRate = min(flowRate, capacity[previous][present] - flow[previous][present])\n",
    "            present = path[present]\n",
    "        # 유량 흘림\n",
    "        present = sink\n",
    "        while present != source:\n",
    "            previous = path[present]\n",
    "            answer[0] += flowRate*cost[previous][present] # 총 비용이 각 간선 비용만큼 증가\n",
    "            flow[previous][present] += flowRate\n",
    "            flow[present][previous] -= flowRate # 음의 유량\n",
    "            present = path[present]\n",
    "        answer[1] += flowRate\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11-4-4. Using linear_sum_assignment Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### feature_row_matching(data, now, clu = 25)\n",
    "- scipy 라이브러리를 통해 할당 문제를 해결한다.\n",
    " - fully-connected 이고, 각 정점을 1:1로 매칭하는 이분 매칭 문제는 할당 문제(Assignment Problem)으로 치환이 가능하다.\n",
    " - 이는 시간복잡도가 O(N^3) 인 헝가리안 알고리즘으로 해결 가능하다.\n",
    " - 특징 맵을 구현하기 위해서는 N * N 번의 작업이 필요하므로 특징 맵 구현을 위한 시간복잡도는 O(N^2C^3)이다.\n",
    " - 기존 유량 문제에 비해 약 10배 빠른 성능으로 계산할 수 있었다.\n",
    "- 실제 feature map 을 생성할 때는 fmap[i][j] = fmap[j][i] 임을 이용하여 삼각행렬만을 계산하였다.\n",
    "- 한 작품이 N개의 작품에 대응하는 최소 비용 행렬 (1:N) 을 return한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_row_matching(data, now, clu = 25):\n",
    "    N = len(data)\n",
    "    clu = len(data[0])\n",
    "    fmap = np.zeros(N)\n",
    "\n",
    "    for i in tqdm(range(N)):\n",
    "        cost_table = np.zeros([clu, clu])\n",
    "        for x, clu_now in enumerate(data[i]):\n",
    "            for y, clu_tar in enumerate(data[now]):\n",
    "                cost_table[x][y] = get_cost(clu_now, clu_tar)\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_table)\n",
    "        answer = 0\n",
    "        for p, q in zip(row_ind, col_ind):\n",
    "            answer += cost_table[p][q]\n",
    "        fmap[i] = answer\n",
    "    return fmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 선호도 기반 이미지 인덱스 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-1. 단순 선호도 행렬 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_idx(scores, peak, length = 9):\n",
    "    result = []\n",
    "    ptg = peak ** scores\n",
    "    ptg = np.cumsum(ptg)\n",
    "    while len(result) != length:\n",
    "        pt = random.random() * ptg[-1]\n",
    "        idx = bisect.bisect_right(ptg, pt)\n",
    "        if scores[idx] != 1 and idx not in result:\n",
    "            result.append(idx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-2. 교차 선호도 행렬 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_idx_cross(scores, rscores, peak, length = 9):\n",
    "    result = []\n",
    "    ptg = peak ** (scores - rscores)\n",
    "    ptg = np.cumsum(ptg)\n",
    "    while len(result) != length:\n",
    "        pt = random.random() * ptg[-1]\n",
    "        idx = bisect.bisect_right(ptg, pt)\n",
    "        if scores[idx] != 1 and idx not in result:\n",
    "            result.append(idx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-3. Visualization of sampled index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_sampled(file_names, idx_list, plotsize = (3, 3), figsize = (12,12)):\n",
    "    plt.figure(figsize = figsize);\n",
    "    for i, idx in enumerate(idx_list):\n",
    "        plt.subplot(plotsize[0], plotsize[1], i + 1)\n",
    "        img = load_img(file_names[idx])\n",
    "        img = np.array(img)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.pause(0.3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 입력 결과에 따른 사용자 선호도 갱신"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13-1. 단순 선호도 및 최댓값 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_score_linearmax(data, scores, idx_list, val_list):\n",
    "    for idx, val in zip(idx_list, val_list):\n",
    "        if val > 0:\n",
    "            scores = np.array([max(x, y) for x, y in zip(scores, data[idx])])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13-2. 교차 선호도 및 최댓값 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_score_crossmax(data, scores, rscores, idx_list, val_list):\n",
    "    for idx, val in zip(idx_list, val_list):\n",
    "        if val > 0:\n",
    "            scores = np.array([max(x, y) for x, y in zip(scores, data[idx])])\n",
    "        else:\n",
    "            rscores = np.array([max(x, y) for x, y in zip(rscores, data[idx])])\n",
    "    return scores, rscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13-3. 단순 선호도 및 Softmax 함수 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_score_softmax(data, scores, idx_list, val_list, peak):\n",
    "    new_scores = np.zeros(len(scores))\n",
    "    for idx, val in zip(idx_list, val_list):\n",
    "        if val > 0:\n",
    "            new_scores += peak ** data[idx]\n",
    "        else:\n",
    "            new_scores += peak ** (1 - data[idx])\n",
    "    return np.array([max(x, y) for x, y in zip(scores, new_scores / (peak * len(idx_list)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13-4. 교차 선호도 및 binary exponential 함수 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_score_crossexp(data, scores, rscores, idx_list, val_list, peak):\n",
    "    cnt = 0\n",
    "    for val in val_list:\n",
    "        if not val > 0:\n",
    "            cnt += 1\n",
    "    new_scores = np.zeros(len(scores))\n",
    "    new_rscores = np.zeros(len(scores))\n",
    "    \n",
    "    for idx, feature in enumerate(data[idx_list].T.copy()):\n",
    "        feature = sorted(np.array([x if y > 0 else -x for x, y in zip(feature, val_list)]))\n",
    "        for i in range(cnt):\n",
    "            new_rscores[idx] += feature[i] * (peak ** (cnt - i - 1))\n",
    "        for i in range(cnt, len(idx_list)):\n",
    "            new_scores[idx] += feature[i] * (peak ** (i - cnt))\n",
    "\n",
    "    new_rscores /= (peak ** cnt) - 1\n",
    "    new_rscores *= peak - 1\n",
    "    new_rscores *= -1\n",
    "    new_scores /= (peak ** (len(idx_list) - cnt)) - 1\n",
    "    new_scores *= peak - 1\n",
    "    new_rscores = np.array([max(x, y) for x, y in zip(rscores, new_rscores)])\n",
    "    new_scores = np.array([max(x, y) for x, y in zip(scores, new_scores)])\n",
    "    \n",
    "    return new_scores, new_rscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 최종 선호도 결과에 기반한 추천"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14-1. Default type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_by_score_cross(file_names, scores, rscores, length = 25, reverse = False):\n",
    "    if reverse:\n",
    "        new_idx = sorted(range(len(scores)), key= lambda i: scores[i] - rscores[i])[:length]\n",
    "    else:\n",
    "        new_idx = sorted(range(len(scores)), key= lambda i: scores[i] - rscores[i])[-length:]\n",
    "        new_idx.reverse()\n",
    "    print(scores[new_idx] - rscores[new_idx])\n",
    "    show_image_sampled(file_names, new_idx, plotsize = (5, 5), figsize = (16, 16))\n",
    "    return new_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14-2. Remove Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_by_score_cross_no_duplicated(file_names, scores, rscores, dup_list, length = 25, reverse = False):\n",
    "    new_idx = sorted(range(len(scores)), key= lambda i: scores[i] - rscores[i])\n",
    "    if not reverse:\n",
    "        new_idx.reverse()\n",
    "    result_idx = []\n",
    "    idx = 0\n",
    "    while len(result_idx) != length:\n",
    "        if new_idx[idx] not in dup_list:\n",
    "            result_idx.append(new_idx[idx])\n",
    "        idx += 1\n",
    "    print(scores[result_idx] - rscores[result_idx])\n",
    "    show_image_sampled(file_names, result_idx, plotsize = (5, 5))\n",
    "    return result_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14-3. Subfunction for check duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_duplicated_list(idx_list, val_list, dup_list):\n",
    "    for idx, val in zip(idx_list, val_list):\n",
    "        if val > 0:\n",
    "            dup_list.append(idx)\n",
    "    return dup_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12~14. Simulating Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_images_v1(data_path, img_path):\n",
    "    file_names = get_file_names(img_path, 'jpg')\n",
    "    fmap = np.load(data_path)\n",
    "    \n",
    "    scores = np.zeros(len(fmap))\n",
    "    rscores = np.zeros(len(fmap))\n",
    "    dup_list = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        idx_list = get_random_idx_cross(scores, rscores, 30)\n",
    "        show_image_sampled(file_names, idx_list)\n",
    "        val_list = list(map(int, input().split()))\n",
    "        dup_list = add_duplicated_list(idx_list, val_list, dup_list)\n",
    "        scores, rscores = get_new_score_crossmax(new_fmap, scores, rscores, idx_list, val_list)\n",
    "    \n",
    "    result_idx = show_image_by_score_cross_no_duplicated(file_names, scores, rscores, dup_list)\n",
    "    result_idx = show_image_by_score_cross_no_duplicated(file_names, scores, rscores, dup_list, reverse = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
